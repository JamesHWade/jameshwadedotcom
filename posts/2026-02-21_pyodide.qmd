---
title: "Python in Your Browser with Pyodide"
author: James H Wade
date: 2026-02-21
description: "Pyodide runs CPython in the browser via WebAssembly. Edit and run every example on this page: no server, no install."
image: https://pyodide.org/en/stable/_static/pyodide-logo.png
execute:
  freeze: auto
  eval: false
format:
  html:
    toc: true
    code-copy: true
    code-link: true
engine: knitr
filters:
  - pyodide
categories:
  - Python
  - WebAssembly
---

Pyodide compiles CPython to WebAssembly. Like [webR for R](../2023-08-13_webr.qmd), it runs Python entirely in your browser: no server, no virtual environment, nothing to install.

NumPy, pandas, matplotlib, and scipy are pre-installed. Other packages can be installed with `micropip`. Variables defined in one cell are available in the next.

Load time is a bit slower than webR (5–10 seconds) because CPython is a larger runtime. Once initialized, subsequent cells are fast.

## NumPy

NumPy is available immediately. The vectorization that makes it fast in a normal Python environment carries over to the WASM build:

```{pyodide-python}
import numpy as np

# Monte Carlo estimate of pi
rng = np.random.default_rng(42)
n = 1_000_000
x, y = rng.uniform(-1, 1, n), rng.uniform(-1, 1, n)
inside = (x**2 + y**2) <= 1.0

pi_estimate = 4 * inside.mean()
print(f"Estimated π: {pi_estimate:.5f}")
print(f"Actual   π: {np.pi:.5f}")
print(f"Error:      {abs(pi_estimate - np.pi):.5f}")
```

Try increasing `n`. The estimate gets more accurate but takes longer. At a million samples you're typically accurate to 3–4 decimal places.

## Matplotlib

Plots render inline. The same Monte Carlo simulation, visualized: points inside the unit circle versus outside.

```{pyodide-python}
import matplotlib.pyplot as plt

# Subsample for plotting (1M dots is too many to render well)
n_plot = 5000
idx = rng.integers(0, n, n_plot)
x_plot, y_plot = x[idx], y[idx]
inside_plot = inside[idx]

fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(x_plot[inside_plot], y_plot[inside_plot],
           s=1, color="#1b6b4a", alpha=0.5, label="Inside")
ax.scatter(x_plot[~inside_plot], y_plot[~inside_plot],
           s=1, color="#c27839", alpha=0.5, label="Outside")

theta = np.linspace(0, 2 * np.pi, 300)
ax.plot(np.cos(theta), np.sin(theta), "k-", linewidth=1)

ax.set_aspect("equal")
ax.set_title(f"Monte Carlo π estimate: {pi_estimate:.4f}")
ax.legend(markerscale=5, framealpha=0.8)
plt.tight_layout()
plt.show()
```

## Pandas

A random walk built as a pandas DataFrame, with a distance-from-origin column:

```{pyodide-python}
import pandas as pd

# Simulate a random walk — same concept as the CLT post
rng2 = np.random.default_rng(0)
n_steps = 500
steps = rng2.choice([-1, 1], size=(n_steps, 2))
position = np.cumsum(steps, axis=0)

df = pd.DataFrame({
    "step": np.arange(n_steps),
    "x": position[:, 0],
    "y": position[:, 1],
    "distance": np.sqrt(position[:, 0]**2 + position[:, 1]**2),
})

print(df.tail(5))
print()
print(df[["x", "y", "distance"]].describe().round(2))
```

```{pyodide-python}
# Plot the walk and distance from origin
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 4.5))

# Path
ax1.plot(df["x"], df["y"], linewidth=0.6, color="#1b6b4a", alpha=0.8)
ax1.scatter(0, 0, color="black", s=60, zorder=5, label="Start")
ax1.scatter(df["x"].iloc[-1], df["y"].iloc[-1],
            color="#c27839", s=60, zorder=5, label="End")
ax1.set_aspect("equal")
ax1.set_title(f"2D random walk ({n_steps} steps)")
ax1.legend(fontsize=9)

# Distance over time
ax2.plot(df["step"], df["distance"], color="#5856d6", linewidth=1)
ax2.axhline(df["distance"].mean(), color="#c27839",
            linestyle="--", linewidth=1, label=f"Mean: {df['distance'].mean():.1f}")
ax2.set_title("Distance from origin over time")
ax2.set_xlabel("Step")
ax2.set_ylabel("Distance")
ax2.legend(fontsize=9)

plt.tight_layout()
plt.show()
```

## The central limit theorem in Python

The same CLT demo from the [R post](../2023-08-13_webr.qmd): exponential population, sample means converging to normal as `n_obs` grows. Change the value and re-run:

```{pyodide-python}
from scipy import stats

n_obs = 5  # try 1, 5, 10, 30
n_sims = 2000

sample_means = [
    np.mean(rng.exponential(scale=2.0, size=n_obs))
    for _ in range(n_sims)
]

fig, ax = plt.subplots(figsize=(8, 4))
ax.hist(sample_means, bins=60, density=True,
        color="#1b6b4a", alpha=0.5, edgecolor="#1b6b4a", linewidth=0.3)

# Normal approximation
mu, sigma = np.mean(sample_means), np.std(sample_means)
x = np.linspace(mu - 4*sigma, mu + 4*sigma, 300)
ax.plot(x, stats.norm.pdf(x, mu, sigma), color="#c27839", linewidth=2,
        label=f"N({mu:.2f}, {sigma:.2f}²)")

ax.set_title(f"n = {n_obs} — sample means from exponential population")
ax.set_xlabel("Sample mean")
ax.legend()
plt.tight_layout()
plt.show()
```

## Installing packages with micropip

Packages not bundled with Pyodide can be installed with `micropip`. Pure-Python packages generally work; packages with C extensions need a WASM build:

```{pyodide-python}
import micropip
await micropip.install("statsmodels")

import statsmodels.api as sm

# Simple OLS: does eruption duration predict waiting time?
# Using the same faithful dataset concept
rng3 = np.random.default_rng(7)
x_data = rng3.uniform(1.5, 5.5, 200)
y_data = 20 + 13 * x_data + rng3.normal(0, 5, 200)

X = sm.add_constant(x_data)
result = sm.OLS(y_data, X).fit()
print(result.summary().tables[1])
```

`micropip.install` is asynchronous, so `await` is required. It downloads from PyPI and installs into the in-browser environment.

## Limitations

A few things don't work in a WASM environment:

- **Threading**: `threading` and `multiprocessing` are unavailable or limited.
- **File I/O**: no access to your local filesystem. Use `io.StringIO` / `io.BytesIO` for in-memory file handling.
- **Network requests**: `requests` won't work. Use `pyodide.http.open_url` or JavaScript's `fetch` via `pyodide.globals`.
- **C-extension packages**: packages that rely on compiled C extensions (like `lightgbm`, `xgboost`) only work if a WASM build exists.

For most data science and statistics work the pre-installed stack (NumPy, pandas, matplotlib, scipy, scikit-learn) covers the common cases. Scikit-learn is fully available. That's a separate post.
