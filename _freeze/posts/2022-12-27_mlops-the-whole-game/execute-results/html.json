{
  "hash": "57cc5871826ec75e8b21cff88fa3e216",
  "result": {
    "markdown": "---\ntitle: \"MLOps: The Whole Game\"\nauthor: James H Wade\ndate: 2022-12-27\nthanks: \"Thank you to the MLOps and tidymodels teams at Posit and all the open source developers that contributed to this fantastic ecosystem.\"\ndescription: An example of model building, model delpoyment, and model monitoring with R using palmerpenguins\nexecute: \n  freeze: true\nformat: \n  html:\n    toc: true\n    code-copy: true\nimage: images/penguins.png\ncategories: \n  - mlops\n  - modeling\n  - vetiver\n  - pins\n  - deployment\n  - R\n---\n\n\n> If we actually know what we're doing we call it engineering. So, this basket of pain, we call something ops.\n>\n> <cite>Peter Wang, [Numerically Speaking Podcast](https://www.anaconda.com/podcast/human-in-the-loop) with Vicky Boykis on ML & MLOps</cite>\n\nMLOps can be overwhelming, but that is not the way it has to be. Posit's MLOps team has made from fantastic advancements over the past year or so, and I hope to show how to demonstrate how easy model deployment can be using Posit's open source tools for MLOps. This includes `{pins}`, `{vetiver}`, and the `{tidymodels}` bundle of packages along with the `{tidyverse}`. The motivation for this post came in part from a [Numerically Speaking podcast](https://www.anaconda.com/podcast/human-in-the-loop) I quote above, and much of the model building is taken from Julia Silge's blog post written to help R users [get started with tidymodels](https://juliasilge.com/blog/palmer-penguins/). I also found inspiration from the [`{vetiver}` documentation page](https://vetiver.rstudio.com/) and the recently revamped [Solutions Engineering Page from Posit](https://solutions.posit.co/gallery/bike_predict/).\n\nThe post covers most of steps in MLOps process, but it's more of a sampler than exhaustive coverage. Think of this as the [\"whole game\"](https://r-pkgs.org/whole-game.html) of MLOps with R.\n\n[![Source: MLOps Team at Posit \\| An overview of MLOps with Vetiver and friends](images/vetiver-mlops.png){fig-alt=\"During the MLOps cycle, we collect data, understand and clean the data, train and evaluate a model, deploy the model, and monitor the deployed model. Monitoring can then lead back to collecting more data. There are many great tools available to understand clean data (like pandas and the tidyverse) and to build models (like tidymodels and scikit-learn). Use the vetiver framework to deploy and monitor your models.\" fig-align=\"center\" width=\"700\"}](https://vetiver.rstudio.com/)\n\n## Model Building\n\n### Load Packages and Set Options\n\nLet's start with the packages that we'll use throughout. `{tidyverse}` and `{tidymodels}` are there, of course. `{pins}`, `{plumbr}`, and `{vetiver}` completes the rest of the Posit set for MLOps, and I use `{gt}` for tables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(pins)\nlibrary(vetiver)\nlibrary(plumber)\nlibrary(palmerpenguins)\nlibrary(gt)\nlibrary(conflicted)\ntidymodels_prefer()\nconflict_prefer(\"penguins\", \"palmerpenguins\")\ntheme_set(theme_bw())\noptions(tidymodels.dark = TRUE)\n```\n:::\n\n\n### Data Exploration\n\nFor this example, we'll use the `palmerpenguins` dataset to demonstrate the overall approach. There is a `{palmerpenguins}` package that contains this data set, and it is also included in the `{modeldata}` package, a part of `{tidymodels}`. We'll use the data from `{palmerpenguins}`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npenguins |>\n  head(4) |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 4\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA\n$ flipper_length_mm <int> 181, 186, 195, NA\n$ body_mass_g       <int> 3750, 3800, 3250, NA\n$ sex               <fct> male, female, female, NA\n$ year              <int> 2007, 2007, 2007, 2007\n```\n:::\n:::\n\n\nAs Julia's [post points out](https://juliasilge.com/blog/palmer-penguins/), differentiating the species with a classification model is quite easy. A trickier model is one that predicts the penguin sex. Let's look at a plot of `flipper_length_mm` versus `bill_length_mm` for each of the species. The color indicates `sex` and the point size indicates `body_mass_g`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npenguins %>%\n  filter(!is.na(sex)) %>%\n  ggplot(aes(\n    x = flipper_length_mm,\n    y = bill_length_mm,\n    color = sex,\n    size = body_mass_g\n  )) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~species)\n```\n\n::: {.cell-output-display}\n![](2022-12-27_mlops-the-whole-game_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n### Model Splitting & Bootstrapping\n\nLet's do a little data cleaning before we move onto modeling. This will include removing any missing `sex` assignments and removing `year` and `island` columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins_df <-\n  penguins |>\n  drop_na(sex) |>\n  select(-year, -island)\n```\n:::\n\n\nThe `{tidymodels}` ecosystem has convenience functions for data splitting that help us do the \"right\" thing during model building. The default split between training and testing set is 75:25.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\npenguin_split <- initial_split(penguins_df, strata = sex)\npenguin_train <- training(penguin_split)\npenguin_test <- testing(penguin_split)\n```\n:::\n\n\n### Preprocess with `{recipes}`\n\nFor preprocessing of the data, let's use `{recipes}`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_rec <-\n  recipe(sex ~ ., data = penguin_train) |>\n  step_YeoJohnson(all_numeric_predictors()) |>\n  step_normalize(all_numeric_predictors()) |>\n  step_dummy(species)\n```\n:::\n\n\nThe `penguin_rec` recipe is a process for preparing data for modeling. It consists of four steps:\n\n1.  The `recipe()` function creates a recipe object, which is a sequence of steps for preprocessing data. The first argument to the function specifies the outcome variable (`sex`) and the predictor variables (`.`, which stands for all variables in the data). The `data` argument specifies the data frame to use for the recipe.\n\n2.  The `step_YeoJohnson()` function applies a Yeo-Johnson transformation to all numeric predictors in the data. This transformation is a type of power transformation that can help normalize data by making it more symmetric and reducing the influence of outliers.\n\n3.  The `step_normalize()` function normalizes all numeric predictors in the data. Normalization scales the data so that it has a mean of 0 and a standard deviation of 1.\n\n4.  The `step_dummy()` function creates dummy variables for the `species` variable. Dummy variables are binary variables that are used to represent categorical variables in a regression model.\n\nOverall, this recipe applies several preprocessing steps to the data in order to prepare it for modeling. The transformed and normalized data, along with the dummy variables, can then be used to build a predictive model.\n\n### Specify the Model\n\nWe'll evaluate three modeling approaches. In the code below, `glm_spec`, `tree_spec`, and `mlp_brulee_spec` are specifications for three different machine learning models: a logistic regression model, a random forest model, and a multi-layer perceptron (MLP) model. The intent with model selection was to demonstrate the use of very different models rather than pick an ideal set of models to screen.\n\nThe `logistic_reg()` function creates a specification for a logistic regression model, and the `set_engine('glm')` function sets the engine for the model to be `'glm'`, which stands for generalized linear model.\n\nThe `rand_forest()` function creates a specification for a random forest model, and the `set_engine('ranger')` function sets the engine for the model to be `'ranger'`, which is an implementation of random forests using the `{ranger}` package. The `set_mode('classification')` function sets the mode of the model to be classification. `set_mode()` is not needed for logistic regression as that model is only used for classification. (Yes, the name is a bad one for what it does.)\n\nThe `mlp()` function creates a specification for an MLP model, and the `set_engine('brulee')` function sets the engine for the model to be `'brulee'`, which uses {`torch}` to specify and fit the neural network. The `tune()` function indicates that the hyperparameters for the model (`hidden_units`, `epochs`, `penalty`, and `learn_rate`) should be tuned.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_spec <-\n  logistic_reg() |>\n  set_engine(\"glm\")\n\ntree_spec <-\n  rand_forest(min_n = tune()) |>\n  set_engine(\"ranger\") |>\n  set_mode(\"classification\")\n\nmlp_brulee_spec <-\n  mlp(\n    hidden_units = tune(), epochs = tune(),\n    penalty = tune(), learn_rate = tune()\n  ) %>%\n  set_engine(\"brulee\") %>%\n  set_mode(\"classification\")\n```\n:::\n\n\n### Create the Workflow Set and Fit Models\n\nBefore we fit the models specified above, let's use cross validation for more robust model evaluation and set the parameters for hyperparameter tuning.\n\nThe `set.seed()` function sets the seed for the random number generator, which is helps improve the reproducibility of the code.\n\nThe `vfold_cv()` function creates a v-fold cross-validation object, which is used to evaluate the performance of a model on different subsets of the data. The `penguin_folds` object stores the folds that will be used for cross-validation.\n\nThe `control_bayes()` creates an object to store the settings for Bayesian optimization. Bayesian optimization is a method for finding the optimal set of hyperparameters for a machine learning model. The `no_improve` argument specifies the number of consecutive iterations with no improvement in the objective function before the optimization process is terminated. The `time_limit` argument specifies the maximum amount of time that the optimization process can run in minutes. The `save_pred` argument specifies whether to save the predictions made during the optimization process.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\npenguin_folds <- vfold_cv(penguin_train)\n\nbayes_control <-\n  control_bayes(no_improve = 10L, time_limit = 20, save_pred = TRUE)\n```\n:::\n\n\nA workflow set combines the recipes and models to fit to our training data. The `{workflowsets}` package is an extension of the `{workflow}` package that allows us to evaluate multiple preprocessing and modeling approaches all together. The `workflow_set()` function creates a workflow set object, which consists of a list of preprocessing recipes in the `preproc` argument and a list of modeling specifications in the `models` argument.\n\nThe `workflow_map()` function applies a function to each element of the workflow set. In this case, we use the `tune_bayes` function, which performs Bayesian optimization using the `{tune}` package. The `iter` argument specifies the maximum number of iterations for each model, the `resamples` argument specifies the cross-validation folds to use, and the `control` argument specifies the settings for Bayesian optimization that we defined above.\n\nOverall, this code creates a workflow set consisting of three models (a logistic regression model, a random forest model, and an MLP model) with preprocessing steps applied to the data, and then performs Bayesian optimization to tune the hyperparameters of the models using cross-validation.[^1]\n\n[^1]: For ease of compute, I don't actually re-calculate the workflow_set in this document. There's a hidden chunk that reads a pinned version of the workflow_set result. For the curious, that's `model_board <- board_local()` and `workflow_set <- mode_board |> pin_read(\"workflow_set\")` .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkflow_set <-\n  workflow_set(\n    preproc = list(penguin_rec),\n    models = list(\n      glm = glm_spec,\n      tree = tree_spec,\n      torch = mlp_brulee_spec\n    )\n  ) |>\n  workflow_map(\"tune_bayes\",\n    iter = 50L,\n    resamples = penguin_folds,\n    control = bayes_control\n  )\n```\n:::\n\n\n\n\nWe can now use `rank_results()` to rank the models in the workflow set based on their performance based on our specified metrics - the area under the receiver operating characteristic curve (ROC AUC). ROC AUC is a measure of a model's ability to distinguish between positive and negative classes. A higher ROC AUC indicates a better-performing model with a maximum value of 1. Using the rank table, we can select the workflow ID for the best performing model.\n\nThroughout many tidymodels packages, `autoplot` is a handy method to rapidly visualize steps in a model workflow. These methods are specified by the package authors, and some `autoplot` methods have some options to customize the output. These are `ggplot` objects, so customize their appearance is easy.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrank_results(workflow_set,\n  rank_metric = \"roc_auc\",\n  select_best = TRUE\n) |>\n  gt()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"ofujbkyrlk\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#ofujbkyrlk .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ofujbkyrlk .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ofujbkyrlk .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#ofujbkyrlk .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ofujbkyrlk .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ofujbkyrlk .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ofujbkyrlk .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ofujbkyrlk .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ofujbkyrlk .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ofujbkyrlk .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ofujbkyrlk .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ofujbkyrlk .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ofujbkyrlk .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#ofujbkyrlk .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ofujbkyrlk .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ofujbkyrlk .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ofujbkyrlk .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ofujbkyrlk .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ofujbkyrlk .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#ofujbkyrlk .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#ofujbkyrlk .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ofujbkyrlk .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#ofujbkyrlk .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#ofujbkyrlk .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ofujbkyrlk .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ofujbkyrlk .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ofujbkyrlk .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ofujbkyrlk .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ofujbkyrlk .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ofujbkyrlk .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ofujbkyrlk .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ofujbkyrlk .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ofujbkyrlk .gt_left {\n  text-align: left;\n}\n\n#ofujbkyrlk .gt_center {\n  text-align: center;\n}\n\n#ofujbkyrlk .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ofujbkyrlk .gt_font_normal {\n  font-weight: normal;\n}\n\n#ofujbkyrlk .gt_font_bold {\n  font-weight: bold;\n}\n\n#ofujbkyrlk .gt_font_italic {\n  font-style: italic;\n}\n\n#ofujbkyrlk .gt_super {\n  font-size: 65%;\n}\n\n#ofujbkyrlk .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#ofujbkyrlk .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#ofujbkyrlk .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#ofujbkyrlk .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#ofujbkyrlk .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#ofujbkyrlk .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#ofujbkyrlk .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\">\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"wflow_id\">wflow_id</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\".config\">.config</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\".metric\">.metric</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"mean\">mean</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"std_err\">std_err</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"n\">n</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"preprocessor\">preprocessor</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"model\">model</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"rank\">rank</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"wflow_id\" class=\"gt_row gt_left\">recipe_torch</td>\n<td headers=\".config\" class=\"gt_row gt_left\">Preprocessor1_Model3</td>\n<td headers=\".metric\" class=\"gt_row gt_left\">accuracy</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">0.8953333</td>\n<td headers=\"std_err\" class=\"gt_row gt_right\">0.02186491</td>\n<td headers=\"n\" class=\"gt_row gt_right\">10</td>\n<td headers=\"preprocessor\" class=\"gt_row gt_left\">recipe</td>\n<td headers=\"model\" class=\"gt_row gt_left\">mlp</td>\n<td headers=\"rank\" class=\"gt_row gt_right\">1</td></tr>\n    <tr><td headers=\"wflow_id\" class=\"gt_row gt_left\">recipe_torch</td>\n<td headers=\".config\" class=\"gt_row gt_left\">Preprocessor1_Model3</td>\n<td headers=\".metric\" class=\"gt_row gt_left\">roc_auc</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">0.9656795</td>\n<td headers=\"std_err\" class=\"gt_row gt_right\">0.01237363</td>\n<td headers=\"n\" class=\"gt_row gt_right\">10</td>\n<td headers=\"preprocessor\" class=\"gt_row gt_left\">recipe</td>\n<td headers=\"model\" class=\"gt_row gt_left\">mlp</td>\n<td headers=\"rank\" class=\"gt_row gt_right\">1</td></tr>\n    <tr><td headers=\"wflow_id\" class=\"gt_row gt_left\">recipe_tree</td>\n<td headers=\".config\" class=\"gt_row gt_left\">Preprocessor1_Model4</td>\n<td headers=\".metric\" class=\"gt_row gt_left\">accuracy</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">0.8916667</td>\n<td headers=\"std_err\" class=\"gt_row gt_right\">0.02309000</td>\n<td headers=\"n\" class=\"gt_row gt_right\">10</td>\n<td headers=\"preprocessor\" class=\"gt_row gt_left\">recipe</td>\n<td headers=\"model\" class=\"gt_row gt_left\">rand_forest</td>\n<td headers=\"rank\" class=\"gt_row gt_right\">2</td></tr>\n    <tr><td headers=\"wflow_id\" class=\"gt_row gt_left\">recipe_tree</td>\n<td headers=\".config\" class=\"gt_row gt_left\">Preprocessor1_Model4</td>\n<td headers=\".metric\" class=\"gt_row gt_left\">roc_auc</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">0.9656541</td>\n<td headers=\"std_err\" class=\"gt_row gt_right\">0.01552447</td>\n<td headers=\"n\" class=\"gt_row gt_right\">10</td>\n<td headers=\"preprocessor\" class=\"gt_row gt_left\">recipe</td>\n<td headers=\"model\" class=\"gt_row gt_left\">rand_forest</td>\n<td headers=\"rank\" class=\"gt_row gt_right\">2</td></tr>\n    <tr><td headers=\"wflow_id\" class=\"gt_row gt_left\">recipe_glm</td>\n<td headers=\".config\" class=\"gt_row gt_left\">Preprocessor1_Model1</td>\n<td headers=\".metric\" class=\"gt_row gt_left\">accuracy</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">0.8956667</td>\n<td headers=\"std_err\" class=\"gt_row gt_right\">0.02540560</td>\n<td headers=\"n\" class=\"gt_row gt_right\">10</td>\n<td headers=\"preprocessor\" class=\"gt_row gt_left\">recipe</td>\n<td headers=\"model\" class=\"gt_row gt_left\">logistic_reg</td>\n<td headers=\"rank\" class=\"gt_row gt_right\">3</td></tr>\n    <tr><td headers=\"wflow_id\" class=\"gt_row gt_left\">recipe_glm</td>\n<td headers=\".config\" class=\"gt_row gt_left\">Preprocessor1_Model1</td>\n<td headers=\".metric\" class=\"gt_row gt_left\">roc_auc</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">0.9639505</td>\n<td headers=\"std_err\" class=\"gt_row gt_right\">0.01352438</td>\n<td headers=\"n\" class=\"gt_row gt_right\">10</td>\n<td headers=\"preprocessor\" class=\"gt_row gt_left\">recipe</td>\n<td headers=\"model\" class=\"gt_row gt_left\">logistic_reg</td>\n<td headers=\"rank\" class=\"gt_row gt_right\">3</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n\n```{.r .cell-code}\nworkflow_set |> autoplot()\n```\n\n::: {.cell-output-display}\n![](2022-12-27_mlops-the-whole-game_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nIn this case `autoplot()` compare the results from each of our workflows showing both `accuracy` and `roc_auc`. Logistic regression appears to be the best model based on these metrics given its comparable performance and lower model complexity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_model_id <- \"recipe_glm\"\n```\n:::\n\n\n### Finalize Model\n\nNow that we have compared our models and identified the top performing one based on `roc_auc`, we can finalize the workflow and fit the model will the full dataset (i.e., not just training data).\n\nIn the code below, the `best_fit` object is extract the best model from the workflow using the workflow ID we selected above. This is done with `workflowsets::extract_workflow_set_result()` and `tune::select_best()` to give us `best_fit`, a tibble of hyperparameters for the best fit model.\n\nWe can then use `finalize_workflow()` to take the hyperparameters from `best_fit` and apply it to the `final_workflow` object. We can then update the fit of the model to use the entire training set instead of folds and evaluate the model on the test set.\n\nThe `collect_metrics()` and `collect_performance()` functions are convenience functions to to check model performance. We can again use `autoplot()` to visualize model results, in this case ROC curves.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_fit <-\n  workflow_set |>\n  extract_workflow_set_result(best_model_id) |>\n  select_best(metric = \"accuracy\")\n\nfinal_workflow <-\n  workflow_set |>\n  extract_workflow(best_model_id) |>\n  finalize_workflow(best_fit)\n\nfinal_fit <-\n  final_workflow |>\n  last_fit(penguin_split)\n\nfinal_fit |>\n  collect_metrics() |>\n  gt()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"seybfbewmz\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#seybfbewmz .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#seybfbewmz .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#seybfbewmz .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#seybfbewmz .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#seybfbewmz .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#seybfbewmz .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#seybfbewmz .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#seybfbewmz .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#seybfbewmz .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#seybfbewmz .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#seybfbewmz .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#seybfbewmz .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#seybfbewmz .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#seybfbewmz .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#seybfbewmz .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#seybfbewmz .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#seybfbewmz .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#seybfbewmz .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#seybfbewmz .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#seybfbewmz .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#seybfbewmz .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#seybfbewmz .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#seybfbewmz .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#seybfbewmz .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#seybfbewmz .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#seybfbewmz .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#seybfbewmz .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#seybfbewmz .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#seybfbewmz .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#seybfbewmz .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#seybfbewmz .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#seybfbewmz .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#seybfbewmz .gt_left {\n  text-align: left;\n}\n\n#seybfbewmz .gt_center {\n  text-align: center;\n}\n\n#seybfbewmz .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#seybfbewmz .gt_font_normal {\n  font-weight: normal;\n}\n\n#seybfbewmz .gt_font_bold {\n  font-weight: bold;\n}\n\n#seybfbewmz .gt_font_italic {\n  font-style: italic;\n}\n\n#seybfbewmz .gt_super {\n  font-size: 65%;\n}\n\n#seybfbewmz .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#seybfbewmz .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#seybfbewmz .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#seybfbewmz .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#seybfbewmz .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#seybfbewmz .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#seybfbewmz .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\">\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\".metric\">.metric</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\".estimator\">.estimator</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\".estimate\">.estimate</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\".config\">.config</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\".metric\" class=\"gt_row gt_left\">accuracy</td>\n<td headers=\".estimator\" class=\"gt_row gt_left\">binary</td>\n<td headers=\".estimate\" class=\"gt_row gt_right\">0.9047619</td>\n<td headers=\".config\" class=\"gt_row gt_left\">Preprocessor1_Model1</td></tr>\n    <tr><td headers=\".metric\" class=\"gt_row gt_left\">roc_auc</td>\n<td headers=\".estimator\" class=\"gt_row gt_left\">binary</td>\n<td headers=\".estimate\" class=\"gt_row gt_right\">0.9705215</td>\n<td headers=\".config\" class=\"gt_row gt_left\">Preprocessor1_Model1</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n\n```{.r .cell-code}\nfinal_fit |>\n  collect_predictions() |>\n  roc_curve(sex, .pred_female) |>\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](2022-12-27_mlops-the-whole-game_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n## Model Deployment\n\nThe [`{vetiver}`](https://rstudio.github.io/vetiver-r/) package provides a set of tools for building, deploying, and managing machine learning models in production. It allows users to easily create, version, and deploy machine learning models to various hosting platforms, such as Posit Connect or a cloud hosting service like Azure.\n\nThe `vetiver_model()` function is used to create an object that stores a machine learning model and its associated metadata, such as the model's name, type, and parameters. `vetiver_pin_write()` and `vetiver_pin_read()` functions are used to write and read `vetiver_model` objects to and from a server.\n\n### Create Vetiver Model\n\nTo deploy our model with `{vetiver}`, we start with our `final_fit` from above, we first need to extract the trained workflow. We can do that with `tune::extract_workflow()`. The trained workflow is what we will deploy as a `vetiver_model`. That means we need to convert it from a workflow to a vetiver model with `vetiver_model()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit_to_deploy <- final_fit |> extract_workflow()\n\nv <- vetiver_model(final_fit_to_deploy, model_name = \"penguins_model\")\n\nv\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n── penguins_model ─ <bundled_workflow> model for deployment \nA glm classification modeling workflow using 5 features\n```\n:::\n:::\n\n\n### Pin Model to Board\n\nThe [`{pins}`](https://pins.rstudio.com/) package is used for storing and managing data sets in a local or remote repository. `{pins}` allows users to \"pin\" data sets to a \"board\", allowing them to be easily accessed and shared with others. Using the pins package, users can create a board, add data sets, and access and retrieve data sets from the board. The `board_rsconnect()` function is used to create a `model_board` or connect to an existing board on Posit Connect (formerly RStudio Connect), which is a connection to a server where a `vetiver_model` can be stored and accessed. We also specify `versioned = TRUE` so that we can version control our vetiver models.\n\nOnce the `model_board` connection is made it's as easy as `vetiver_pin_write()` to \"pin\" our model to the model board and `vetiver_pin_read()` to access it. In this case, we must specify the username of the author of the pin, which in this case is `james`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_board <- board_local(versioned = TRUE)\nmodel_board |> vetiver_pin_write(v)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCreating new version '20221228T000205Z-9c561'\nWriting to pin 'penguins_model'\n\nCreate a Model Card for your published model\n• Model Cards provide a framework for transparent, responsible reporting\n• Use the vetiver `.Rmd` template as a place to start\n```\n:::\n\n```{.r .cell-code}\nmodel_board |> vetiver_pin_read(\"penguins_model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n── penguins_model ─ <bundled_workflow> model for deployment \nA glm classification modeling workflow using 5 features\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_board <- board_rsconnect(versioned = TRUE)\nmodel_board |> vetiver_pin_write(v)\nmodel_board |> vetiver_pin_read(\"penguins_model\")\n```\n:::\n\n\n### Create Model API\n\nOur next step is to use `{vetiver}` and [`{plumber}`](https://www.rplumber.io/) packages to create an API for our vetiver model, which can then be accessed and used to make predictions or perform other tasks via an HTTP request. `pr()` creates a new plumber router, and `vetiver_api(v)` adds a `POST` endpoint to make endpoints from a trained vetiver model. `vetiver_write_plumber()` creates a `plumber.R` file that specifies the model version of the model we pinned to our model dashboard with `vetiver_pin_write()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npr() |>\n  vetiver_api(v)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Plumber router with 2 endpoints, 4 filters, and 1 sub-router.\n# Use `pr_run()` on this object to start the API.\n├──[queryString]\n├──[body]\n├──[cookieParser]\n├──[sharedSecret]\n├──/logo\n│  │ # Plumber static router serving from directory: /Library/Frameworks/R.framework/Versions/4.2/Resources/library/vetiver\n├──/ping (GET)\n└──/predict (POST)\n```\n:::\n\n```{.r .cell-code}\nvetiver_write_plumber(model_board, \"penguins_model\")\n```\n:::\n\n\nHere is an example of the `plumber.R` file generated by `vetiver_write_pumber()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generated by the vetiver package; edit with care\n\nlibrary(pins)\nlibrary(plumber)\nlibrary(rapidoc)\nlibrary(vetiver)\n\n# Packages needed to generate model predictions\nif (FALSE) {\n  library(parsnip)\n  library(recipes)\n  library(stats)\n  library(workflows)\n}\nb <- board_rsconnect(\"envvar\", server = \"https://connect.mycompany.com\")\nv <- vetiver_pin_read(b, \"penguins_model\", version = \"6926\")\n\n#* @plumber\nfunction(pr) {\n  pr %>% vetiver_api(v)\n}\n```\n:::\n\n\n### Deploy API to Posit Connect\n\nThis model can be hosted in a variety of locations. One of the easiest to use is Posit Connect. `vetiver_deploy_rsconnect()` does that for us. All we need to specify is the name of the pinned vetiver model and the model board.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvetiver_deploy_rsconnect(\n  board = model_board,\n  name = \"penguins_model\",\n  account = \"james\"\n)\n```\n:::\n\n\n### Deploying Elsewhere\n\nIf Posit Connect is not the right place for our model, `vetiver_write_docker` creates a `dockerfile` and `renv.lock`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvetiver_write_docker(v)\n```\n:::\n\n\nHere is an example of the dockerfile that is generated.\n\n``` dockerfile\n# Generated by the vetiver package; edit with care\n\nFROM rocker/r-ver:4.2.1\nENV RENV_CONFIG_REPOS_OVERRIDE https://packagemanager.rstudio.com/cran/latest\n\nRUN apt-get update -qq && apt-get install -y --no-install-recommends \\\nlibcurl4-openssl-dev \\\nlibicu-dev \\\nlibsodium-dev \\\nlibssl-dev \\\nmake \\\nzlib1g-dev \\\n&& apt-get clean\n\nCOPY vetiver_renv.lock renv.lock\nRUN Rscript -e \"install.packages('renv')\"\nRUN Rscript -e \"renv::restore()\"\nCOPY plumber.R /opt/ml/plumber.R\nEXPOSE 8000\nENTRYPOINT [\"R\", \"-e\", \"pr <- plumber::plumb('/opt/ml/plumber.R'); pr$run(host = '0.0.0.0', port = 8000)\"]\n```\n\n### Using the API to Make Predictions\n\nThe api deployment site url `https://connect.mycompany.com/penguins`, and the prediction endpoint is `https://connect.mycompany.com/penguins/predict`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nendpoint <-\n  vetiver_endpoint(\"https://connect.mycompany.com/penguins/predict\")\n```\n:::\n\n\nWe can make endpoints with the endpoint using `predict`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_data <- tibble(\n  species = \"Adelie\",\n  bill_length_mm = 40.5,\n  bill_depth_mm = 18.9,\n  flipper_length_mm = 180,\n  body_mass_g = 3950\n)\n\npredict(endpoint, new_data)\n```\n:::\n\n\nWe can also use `{httr}` to call the API. In most cases, it is easier for R users to use `predict` rather than `httr::POST`. However, were this model written in another language, making predictions using `{httr}` would likely bet the best approach.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(httr)\nurl <- \"https://connect.mycompany.com/penguins/predict\"\njson_data <- jsonlite::toJSON(new_data)\nresponse <- POST(url, body = json_data)\nresponse\ncontent(response)\n```\n:::\n\n\nAvoiding a language-specific approach altogether, we can use `curl` in a terminal to make API calls.\n\n``` {.bash filename=\"Terminal\"}\n#| file\ncurl -X POST \"https://connect.mycompany.com/penguins/predict\" \\\n -H \"Accept: application/json\" \\\n -H \"Content-Type: application/json\" \\\n -d '[{\"species\":\"Adelie\",\"bill_length_mm\":0.5,\"bill_depth_mm\":0.5,\"flipper_length_mm\":0,\"body_mass_g\":0}]' \\\n```\n\n## Model Monitoring\n\nAfter deployment, we need to monitor model performance. The [MLOps with vetiver monitoring page](https://vetiver.rstudio.com/get-started/monitor.html) describes this well:\n\n> Machine learning can break quietly; a model can continue returning predictions without error, even if it is performing poorly. Often these quiet performance problems are discussed as types of model drift; data drift can occur when the statistical distribution of an input feature changes, or concept drift occurs when there is change in the relationship between the input features and the outcome.\n>\n> Without monitoring for degradation, this silent failure can continue undiagnosed. The vetiver framework offers functions to fluently compute, store, and plot model metrics. These functions are particularly suited to monitoring your model using multiple performance metrics over time. Effective model monitoring is not \"one size fits all\", but instead depends on choosing appropriate metrics and time aggregation for a given application.\n\nAs a baseline for model performance, we can start by using our training set to create original metrics for the model. We also simulate a `date_obs` column. In a real example, we should use the date the data was collected.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\npenguin_train_by_date <-\n  penguin_train |>\n  rowwise() |>\n  mutate(date_obs = Sys.Date() - sample(4:10, 1)) |>\n  ungroup() |>\n  arrange(date_obs)\n\noriginal_metrics <-\n  augment(v, penguin_train_by_date) |>\n  vetiver_compute_metrics(\n    date_var = date_obs,\n    period = \"day\",\n    truth = \"sex\",\n    estimate = \".pred_class\"\n  )\n\nvetiver_plot_metrics(original_metrics)\n```\n\n::: {.cell-output-display}\n![](2022-12-27_mlops-the-whole-game_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nWe can pin the model performance metrics, just as we did with the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_board %>%\n  pin_write(original_metrics, \"penguin_metrics\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nGuessing `type = 'rds'`\nCreating new version '20221228T000206Z-3e18d'\nWriting to pin 'penguin_metrics'\n```\n:::\n:::\n\n\nTo simulate the model going \"live\", let's use the test set to add more predictions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\npenguin_test_by_date <-\n  penguin_test |>\n  rowwise() |>\n  mutate(date_obs = Sys.Date() - sample(1:3, 1)) |>\n  ungroup() |>\n  arrange(date_obs)\n\nv <-\n  model_board |>\n  vetiver_pin_read(\"penguins_model\")\n\nnew_metrics <-\n  augment(v, penguin_test_by_date) |>\n  vetiver_compute_metrics(\n    date_var = date_obs,\n    period = \"day\",\n    truth = \"sex\",\n    estimate = \".pred_class\"\n  )\n\nmodel_board |>\n  vetiver_pin_metrics(new_metrics, \"penguin_metrics\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCreating new version '20221228T000206Z-7c132'\nWriting to pin 'penguin_metrics'\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 20 × 5\n   .index        .n .metric  .estimator .estimate\n   <date>     <int> <chr>    <chr>          <dbl>\n 1 2022-12-17    32 accuracy binary         0.844\n 2 2022-12-17    32 kap      binary         0.688\n 3 2022-12-18    45 accuracy binary         0.911\n 4 2022-12-18    45 kap      binary         0.82 \n 5 2022-12-19    29 accuracy binary         0.966\n 6 2022-12-19    29 kap      binary         0.931\n 7 2022-12-20    34 accuracy binary         0.912\n 8 2022-12-20    34 kap      binary         0.820\n 9 2022-12-21    44 accuracy binary         0.886\n10 2022-12-21    44 kap      binary         0.759\n11 2022-12-22    31 accuracy binary         0.903\n12 2022-12-22    31 kap      binary         0.807\n13 2022-12-23    34 accuracy binary         0.941\n14 2022-12-23    34 kap      binary         0.881\n15 2022-12-24    30 accuracy binary         0.867\n16 2022-12-24    30 kap      binary         0.724\n17 2022-12-25    30 accuracy binary         0.933\n18 2022-12-25    30 kap      binary         0.867\n19 2022-12-26    24 accuracy binary         0.917\n20 2022-12-26    24 kap      binary         0.833\n```\n:::\n:::\n\n\nNow that we've updated the model metrics, we can plot model performance over time , again using the `vetiver_plot_metrics()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmonitoring_metrics <-\n  model_board |> pin_read(\"penguin_metrics\")\nvetiver_plot_metrics(monitoring_metrics)\n```\n\n::: {.cell-output-display}\n![](2022-12-27_mlops-the-whole-game_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "2022-12-27_mlops-the-whole-game_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}