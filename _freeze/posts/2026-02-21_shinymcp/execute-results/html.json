{
  "hash": "6d2d0290495e28b235018b3acfc76fb8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Turning Shiny Apps into MCP Apps with shinymcp\"\nauthor: James H Wade\ndate: 2026-02-21\ndescription: \"shinymcp converts Shiny apps into MCP Apps: interactive UIs that render directly inside AI chat interfaces like Claude Desktop.\"\nimage: https://raw.githubusercontent.com/JamesHWade/shinymcp/main/man/figures/logo.png\nexecute:\n  freeze: auto\n  eval: false\nformat:\n  html:\n    toc: true\n    code-copy: true\n    code-link: true\ncategories:\n  - Shiny\n  - MCP\n  - AI\n  - R\n  - ellmer\n---\n\nShiny apps live on a server. You visit a URL, you click around, you leave. What if the app could live inside the conversation you're already having with an AI assistant?\n\nThat's what [MCP Apps](https://modelcontextprotocol.io/) enable, and [shinymcp](https://github.com/JamesHWade/shinymcp) is how you build them from R.\n\n## What's an MCP App?\n\nThe [Model Context Protocol](https://modelcontextprotocol.io/) is an open standard for connecting AI assistants to external tools and data. MCP servers expose tools that an AI model can call: search a database, run a computation, fetch a file. MCP Apps extend this idea to include a UI. Instead of the model calling a function and getting text back, the user sees an interactive interface rendered directly in the chat.\n\nIn practice, a Shiny-style dashboard can appear inline in Claude Desktop. The user changes a dropdown, the tool fires, the output updates, all inside the conversation. No separate browser tab, no URL to share, no deployment to manage.\n\n## Quick start\n\nInstall shinymcp from GitHub:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"pak\")\npak::pak(\"JamesHWade/shinymcp\")\n```\n:::\n\n\nAn MCP App has two parts: **UI components** that render in the chat, and **tools** that run R code when inputs change. Here's a minimal dataset explorer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(shinymcp)\nlibrary(bslib)\n\nui <- page_sidebar(\n  theme = bs_theme(preset = \"shiny\"),\n  title = \"Dataset Explorer\",\n  sidebar = sidebar(\n    shiny::selectInput(\"dataset\", \"Choose dataset\", c(\"mtcars\", \"iris\", \"pressure\"))\n  ),\n  card(\n    card_header(\"Summary\"),\n    mcp_text(\"summary\")\n  )\n)\n\ntools <- list(\n  ellmer::tool(\n    fun = function(dataset = \"mtcars\") {\n      data <- get(dataset, envir = asNamespace(\"datasets\"))\n      paste(capture.output(summary(data)), collapse = \"\\n\")\n    },\n    name = \"get_summary\",\n    description = \"Get summary statistics for the selected dataset\",\n    arguments = list(\n      dataset = ellmer::type_string(\"Dataset name\")\n    )\n  )\n)\n\napp <- mcp_app(ui, tools, name = \"dataset-explorer\")\nserve(app)\n```\n:::\n\n\nSave this as `app.R`, then register it in your Claude Desktop config:\n\n```json\n{\n  \"mcpServers\": {\n    \"dataset-explorer\": {\n      \"command\": \"Rscript\",\n      \"args\": [\"/path/to/app.R\"]\n    }\n  }\n}\n```\n\nRestart Claude Desktop and invoke the tool. An interactive UI appears inline in the conversation. Changing the dropdown calls the tool and updates the output without a page reload.\n\n![shinymcp demo showing an interactive dashboard inside Claude Desktop](https://raw.githubusercontent.com/JamesHWade/shinymcp/main/man/figures/demo.gif)\n\n## The core idea: flatten your reactive graph\n\nIf you've built Shiny apps, you think in reactive expressions: inputs feed into reactives, which feed into outputs. In an MCP App, you flatten that graph into tool functions.\n\nEach connected group of inputs, reactives, and outputs becomes a single tool. The tool takes input values as arguments and returns a named list of outputs. Here's what the translation looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- Shiny server ---\nserver <- function(input, output, session) {\n  filtered <- reactive({\n    penguins[penguins$species == input$species, ]\n  })\n  output$scatter <- renderPlot({\n    ggplot(filtered(), aes(bill_length_mm, bill_depth_mm)) + geom_point()\n  })\n  output$stats <- renderPrint({\n    summary(filtered())\n  })\n}\n\n# --- Equivalent MCP App tool ---\nellmer::tool(\n  fun = function(species = \"Adelie\") {\n    filtered <- penguins[penguins$species == species, ]\n\n    # Render plot to base64 PNG\n    p <- ggplot2::ggplot(filtered, ggplot2::aes(bill_length_mm, bill_depth_mm)) +\n      ggplot2::geom_point()\n    tmp <- tempfile(fileext = \".png\")\n    ggplot2::ggsave(tmp, p, width = 7, height = 4, dpi = 144)\n    on.exit(unlink(tmp))\n\n    list(\n      scatter = base64enc::base64encode(tmp),\n      stats = paste(capture.output(summary(filtered)), collapse = \"\\n\")\n    )\n  },\n  name = \"explore\",\n  description = \"Filter and visualize penguins\",\n  arguments = list(\n    species = ellmer::type_string(\"Penguin species\")\n  )\n)\n```\n:::\n\n\nThe return keys (`scatter`, `stats`) must match the output IDs in the UI (`mcp_plot(\"scatter\")`, `mcp_text(\"stats\")`). The bridge routes each value to the right element.\n\n## How the bridge works\n\nMCP Apps render inside sandboxed iframes in the AI chat interface. A lightweight JavaScript bridge (no npm dependencies) handles the communication:\n\n1. User changes an input\n2. The bridge detects which form elements are inputs (by matching tool argument names to element `id` attributes) and collects their values\n3. Bridge sends a `tools/call` request to the host via `postMessage`\n4. Host proxies the call to the MCP server (your R process)\n5. R tool function runs and returns results\n6. Bridge updates the output elements\n\nThe input auto-detection is the key convenience. If your `selectInput` has `id = \"species\"` and your tool has an argument called `species`, the bridge wires them together automatically. For edge cases where ids don't match argument names, `mcp_input()` lets you explicitly mark an element.\n\n## Automatic conversion\n\nIf you have an existing Shiny app you want to convert, shinymcp includes a parse-analyze-generate pipeline:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconvert_app(\"path/to/my-shiny-app\")\n```\n:::\n\n\nThis parses the UI and server code, maps the reactive dependency graph into tool groups, and writes a working MCP App with tools, components, and a server entrypoint. The generated tool bodies contain placeholders for the computation logic.\n\nFor complex apps with dynamic UI, modules, or file uploads, shinymcp also ships a [deputy](https://github.com/JamesHWade/deputy) skill that guides an AI agent through the conversion process.\n\n## Output components\n\nshinymcp provides output components that correspond to standard Shiny outputs:\n\n| Shiny | shinymcp | What the tool returns |\n|---|---|---|\n| `textOutput()` | `mcp_text()` | Plain text string |\n| `plotOutput()` | `mcp_plot()` | Base64-encoded PNG |\n| `tableOutput()` | `mcp_table()` | HTML table string |\n| `htmlOutput()` | `mcp_html()` | Raw HTML |\n\nFor inputs, you use the standard `shiny` and `bslib` inputs you already know: `selectInput`, `numericInput`, `checkboxInput`, etc. The bridge auto-detects them.\n\n## Why this matters\n\nThe interesting part isn't the technology. It's the interaction pattern. When a Shiny app lives inside a chat, the AI can see and respond to what the user is doing in the app. The model has context about both the conversation and the interactive exploration.\n\nI'm still early in figuring out what this enables. If you build something with it, I'd like to hear about it.\n\n## Resources\n\n- [shinymcp on GitHub](https://github.com/JamesHWade/shinymcp)\n- [shinymcp documentation](https://jameshwade.github.io/shinymcp/)\n- [ellmer](https://ellmer.tidyverse.org/), the LLM framework shinymcp builds on\n- [MCP specification](https://modelcontextprotocol.io/)\n- [bslib](https://rstudio.github.io/bslib/), Bootstrap layout and theming for the UI\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}